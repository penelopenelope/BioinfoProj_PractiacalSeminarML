# -*- coding: utf-8 -*-
"""prediction.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/13PT-T1QmYNaIEAAB12RnGO5b4BUPt0lV
"""

import torch
from PIL import Image
from torchvision import transforms

import numpy as np 
import pandas as pd 
import matplotlib.pyplot as plt
from matplotlib.image import imread
import seaborn as sns
import random
import cv2
import copy

import torch.nn as nn
import torch.nn.functional as F
import torchvision
import torchvision.transforms as tt
import torchvision.models as models
from torchvision.datasets import ImageFolder
from torchvision.utils import make_grid
from torch.utils.data import random_split, DataLoader

from mlxtend.plotting import plot_confusion_matrix
from sklearn.metrics import confusion_matrix

import os

class DysplasiaModelBase(nn.Module):
    
    # this is for loading the batch of train image and outputting its loss, accuracy 
    # & predictions
    def training_step(self, batch, weight):
        images,labels = batch
        out = self(images)                                      # generate predictions
        loss = F.cross_entropy(out, labels, weight=weight)      # weighted compute loss
        acc,preds = accuracy(out, labels)                       # calculate accuracy
        
        return {'train_loss': loss, 'train_acc':acc}
       
    # this is for computing the train average loss and acc for each epoch
    def train_epoch_end(self, outputs):
        batch_losses = [x['train_loss'] for x in outputs]       # get all the batches loss
        epoch_loss = torch.stack(batch_losses).mean()           # combine losses
        batch_accs = [x['train_acc'] for x in outputs]          # get all the batches acc
        epoch_acc = torch.stack(batch_accs).mean()              # combine accuracies
        
        return {'train_loss': epoch_loss.item(), 'train_acc': epoch_acc.item()}
    
    # this is for loading the batch of val/test image and outputting its loss, accuracy, 
    # predictions & labels
    def validation_step(self, batch):
        images,labels = batch
        out = self(images)                                      # generate predictions
        loss = F.cross_entropy(out, labels)                     # compute loss
        acc,preds = accuracy(out, labels)                       # calculate acc & get preds
        
        return {'val_loss': loss.detach(), 'val_acc':acc.detach(), 
                'preds':preds.detach(), 'labels':labels.detach()}
    # detach extracts only the needed number, or other numbers will crowd memory
    
    # this is for computing the validation average loss and acc for each epoch
    def validation_epoch_end(self, outputs):
        batch_losses = [x['val_loss'] for x in outputs]         # get all the batches loss
        epoch_loss = torch.stack(batch_losses).mean()           # combine losses
        batch_accs = [x['val_acc'] for x in outputs]            # get all the batches acc
        epoch_acc = torch.stack(batch_accs).mean()              # combine accuracies
        
        return {'val_loss': epoch_loss.item(), 'val_acc': epoch_acc.item()}

    # this is for printing out the results after each epoch
    def epoch_end(self, epoch, train_result, val_result):
        print('Epoch [{}], train_loss: {:.4f}, train_acc: {:.4f}, val_loss: {:.4f}, val_acc: {:.4f}'.
              format(epoch+1, train_result['train_loss'], train_result['train_acc'],
                     val_result['val_loss'], val_result['val_acc']))
    
    # this is for using on the test set, it outputs the average loss and acc, 
    # and outputs the predictions
    def test_prediction(self, outputs):
        batch_losses = [x['val_loss'] for x in outputs]
        epoch_loss = torch.stack(batch_losses).mean()           # combine losses
        batch_accs = [x['val_acc'] for x in outputs]
        epoch_acc = torch.stack(batch_accs).mean()              # combine accuracies
        # combine predictions
        batch_preds = [pred for x in outputs for pred in x['preds'].tolist()] 
        # combine labels
        batch_labels = [lab for x in outputs for lab in x['labels'].tolist()]  
        
        return {'test_loss': epoch_loss.item(), 'test_acc': epoch_acc.item(),
                'test_preds': batch_preds, 'test_labels': batch_labels}

class DysplasiaResnet(DysplasiaModelBase):
    def __init__(self):
        super().__init__()
        # Use a pretrained model
        self.network = models.resnet50(pretrained=True)
        # Freeze training for all layers before classifier
        for param in self.network.fc.parameters():
            param.require_grad = False  
        num_features = self.network.fc.in_features # get number of in features of last layer
        self.network.fc = nn.Linear(num_features, 2) # replace model classifier
    
    def forward(self, xb):
        return self.network(xb)
    
# Or if InceptionV3
class DysplasiaInceptionV3(DysplasiaModelBase):
    def __init__(self):
        super().__init__()
        # Use a pretrained model
        self.network = models.inception_v3(aux_logits=False,pretrained=True)
        # Freeze training for all layers before classifier
        for param in self.network.fc.parameters():
            param.require_grad = False  
        num_features = self.network.fc.in_features # get number of in features of last layer
        self.network.fc = nn.Linear(num_features, 2) # replace model classifier
    
    def forward(self, xb):
        return self.network(xb)

device = torch.device('cuda')
transform=transforms.Compose([
            transforms.Resize(255),
            transforms.CenterCrop(224),
            transforms.ToTensor()])

# single image prediction

def load_checkpoint(filepath):
    checkpoint = torch.load(filepath)
    model = checkpoint['model']
    model.load_state_dict(checkpoint['state_dict'])
    for parameter in model.parameters():
        parameter.requires_grad = False

    model.eval()
    return model

def predict_single_img(model_path, img_path):
    
    global classes
    
    # model loading
    model = load_checkpoint(model_path)
    model = model.to(device)
    
    #image loading
    img=Image.open(img_path)
    img=transform(img).unsqueeze(0)
    img_ = img.to(device)
    
    # prediction
    outputs = model(img_)
    # print(outputs)

    _, classification_int = torch.max(outputs, 1)
    # print(classification_int)

    normal_confidence = torch.nn.functional.softmax(outputs,dim=1)[0][1]*100
    print('Normal prediction confidence:', '%.6f' % float(normal_confidence), '%')

    atrophy_confidence = torch.nn.functional.softmax(outputs,dim=1)[0][0]*100
    print('Atrophy prediction confidence:', '%.6f' % float(atrophy_confidence), '%')
    
    classification = classes[classification_int[0]]
    print('Classification:', classification)
    
    return classification, atrophy_confidence, outputs


def draw_hist(prediction_outputs, img_path, classification):
    
    x = float(torch.nn.functional.softmax(prediction_outputs,dim=1)[0][0])
    y = float(torch.nn.functional.softmax(prediction_outputs,dim=1)[0][1])
    prediction = (x, y)
    hist = pd.DataFrame({'pred': prediction}, index = classes)

    plt.figure(figsize=(16, 5))
    ax = plt.subplot(1, 2, 1)

    image = Image.open(img_path)

    np.array(image).shape
    ax.imshow(image)
    plt.axis('off')
    ax.set_title(classification)

    ax = plt.subplot(1, 2, 2)
    hist.plot.barh(color='blue', edgecolor='k', ax=ax)
    plt.xlabel('Predicted Probability')
    plt.tight_layout()

model_path = '../input/inceptionv3-model/InceptionV3_FinalVersion_Siwen_acc91.43.pth'
img_path = '../input/pred-img/test1_a.jpg'
img_path = '../input/pred-img/test2_n.jpg'
classes = ['Atrophy', 'Normal']

clas, confidenc, output = predict_single_img(model_path, img_path)
draw_hist(output, img_path, clas)

# batch images prediction

import os

# folder_path = '../input/pred-non-atrophy-imgs'
folder_path = '../input/pred-atrophy-imgs'

def predict_batch_imgs(imgs_path, model_path):
    
    # model loading
    model = load_checkpoint(model_path)
    model = model.to(device)

    for root, dirs, files in os.walk(imgs_path):
        for file in files:
            img=Image.open(os.path.join(root,file))
            img=transform(img).unsqueeze(0)
            img_ = img.to(device)
            outputs = model(img_)
            # print(outputs)
            __, classification_ = torch.max(outputs, 1)
            draw_hist(outputs, os.path.join(root,file), classes[classification_[0]])
            conf = torch.nn.functional.softmax(outputs,dim=1)[0]
            # print(conf)
            print(os.path.join(root,file))
            
            normal_confidence = torch.nn.functional.softmax(outputs,dim=1)[0][1]*100
            print('Normal prediction confidence:', '%.6f' % float(normal_confidence), '%')

            atrophy_confidence = torch.nn.functional.softmax(outputs,dim=1)[0][0]*100
            print('Atrophy prediction confidence:', '%.6f' % float(atrophy_confidence), '%')
    
            print('Classification:', classes[classification_[0]])
            
predict_batch_imgs(folder_path, model_path)